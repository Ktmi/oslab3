diff --git a/arch/x86/entry/syscalls/syscall_64.tbl b/arch/x86/entry/syscalls/syscall_64.tbl
index c29976eca4a8..cb9ae049e25f 100644
--- a/arch/x86/entry/syscalls/syscall_64.tbl
+++ b/arch/x86/entry/syscalls/syscall_64.tbl
@@ -357,6 +357,8 @@
 433	common	fspick			__x64_sys_fspick
 434	common	pidfd_open		__x64_sys_pidfd_open
 435	common	clone3			__x64_sys_clone3/ptregs
+436	64	get_slob_amt_claimed	__x64_sys_get_slob_amt_claimed
+437	64	get_slob_amt_free	__x64_sys_get_slob_amt_free
 
 #
 # x32-specific system call numbers start at 512 to avoid cache impact
diff --git a/include/linux/syscalls.h b/include/linux/syscalls.h
index f7c561c4dcdd..53b9b251da4f 100644
--- a/include/linux/syscalls.h
+++ b/include/linux/syscalls.h
@@ -1421,4 +1421,7 @@ long compat_ksys_semtimedop(int semid, struct sembuf __user *tsems,
 			    unsigned int nsops,
 			    const struct old_timespec32 __user *timeout);
 
+asmlinkage long sys_get_slob_amt_claimed(void);
+asmlinkage long sys_get_slob_amt_free(void);
+
 #endif
diff --git a/mm/slob.c b/mm/slob.c
index fa53e9f73893..cf0a056c7148 100644
--- a/mm/slob.c
+++ b/mm/slob.c
@@ -58,6 +58,7 @@
  */
 
 #include <linux/kernel.h>
+#include <linux/syscalls.h>
 #include <linux/slab.h>
 
 #include <linux/mm.h>
@@ -102,6 +103,15 @@ static LIST_HEAD(free_slob_small);
 static LIST_HEAD(free_slob_medium);
 static LIST_HEAD(free_slob_large);
 
+/*
+ * Statistics variables
+ */
+#define HISTORY_LENGTH 100
+long amt_claimed[HISTORY_LENGTH];
+long amt_free[HISTORY_LENGTH];
+int history_iterator = 0;
+
+
 /*
  * slob_page_free: true for pages on free_slob_pages list.
  */
@@ -219,6 +229,21 @@ static void slob_free_pages(void *b, int order)
 	__free_pages(sp, order);
 }
 
+
+
+/*
+ * Modified slob_page_alloc() to use best fit algorithm.
+ * Rather than immediately allocating when a fit is found,
+ * the system now stores the location of the first available
+ * fit, then compares that with the next available fit.
+ * If the next available fit is a better fit, then
+ * that is stored instead. The system continues to do this
+ * until the list of possible fits has been exhausted.
+ * Once all possible fits are exhausted, and a best
+ * available fit has been found, the system runs the allocation
+ * algorithm on the best possible fit.
+ */
+
 /*
  * slob_page_alloc() - Allocate a slob block within a given slob_page sp.
  * @sp: Page to look in.
@@ -239,6 +264,9 @@ static void *slob_page_alloc(struct page *sp, size_t size, int align,
 {
 	slob_t *prev, *cur, *aligned = NULL;
 	int delta = 0, units = SLOB_UNITS(size);
+	
+	slob_t *best_fit_pos = NULL;
+	slob_t *best_fit_pos_prev = NULL;
 
 	*page_removed_from_list = false;
 	for (prev = NULL, cur = sp->freelist; ; prev = cur, cur = slob_next(cur)) {
@@ -257,6 +285,33 @@ static void *slob_page_alloc(struct page *sp, size_t size, int align,
 				 - align_offset);
 			delta = aligned - cur;
 		}
+		
+		if (avail >= units + delta) {
+			if (best_fit_pos) {
+				if (avail <= slob_units(best_fit_pos)) {
+					best_fit_pos = cur;
+					best_fit_pos_prev = prev;
+				}
+			}
+			else {
+				best_fit_pos = cur;
+				best_fit_pos_prev = prev;
+			}
+		}
+		if (slob_last(cur))
+			break;
+	}
+	if(best_fit_pos)
+	{
+		cur = best_fit_pos;
+		prev = best_fit_pos_prev;
+		slobidx_t avail = slob_units(cur);
+		if (align) {
+			aligned = (slob_t *)
+				(ALIGN((unsigned long)cur + align_offset, align)
+				 - align_offset);
+			delta = aligned - cur;
+		}
 		if (avail >= units + delta) { /* room enough? */
 			slob_t *next;
 
@@ -290,11 +345,24 @@ static void *slob_page_alloc(struct page *sp, size_t size, int align,
 			}
 			return cur;
 		}
-		if (slob_last(cur))
-			return NULL;
 	}
+	return NULL;
 }
 
+/*
+ * Instrumented slob_alloc, to record fragmentation for small
+ * allocations. At the if (!b) after b = slob_page_alloc
+ * has been called, the system will add the amount of
+ * free bytes in the called page to a temporary variable,
+ * temp_amt_free.
+ * After the routine is done, we check if we were using
+ * the free_slob_small list, and if so, we stored
+ * our gathered statistics in global arrays.
+ * The value from temp_amt_free is stored in the
+ * amt_free array, and the value from size is stored
+ * in amt_claimed.
+ */
+
 /*
  * slob_alloc: entry point into the slob allocator.
  */
@@ -307,6 +375,9 @@ static void *slob_alloc(size_t size, gfp_t gfp, int align, int node,
 	unsigned long flags;
 	bool _unused;
 
+	/* Variable to keep track of free memory that we couldn't use*/
+	long temp_amt_free = 0;
+
 	if (size < SLOB_BREAK1)
 		slob_list = &free_slob_small;
 	else if (size < SLOB_BREAK2)
@@ -331,9 +402,18 @@ static void *slob_alloc(size_t size, gfp_t gfp, int align, int node,
 			continue;
 
 		b = slob_page_alloc(sp, size, align, align_offset, &page_removed_from_list);
-		if (!b)
-			continue;
 
+		/*
+		 * Every time the system fails to make an allocation, despite
+		 * there being enough units for an allocation, but the memory
+		 * is to fragmented to make that allocation, we record
+		 * the amount of free space we where denied.
+		 */
+		if (!b) {
+			if (slob_list == &free_slob_small)
+				temp_amt_free += sp->units;
+			continue;
+		}
 		/*
 		 * If slob_page_alloc() removed sp from the list then we
 		 * cannot call list functions on sp.  If so allocation
@@ -373,6 +453,16 @@ static void *slob_alloc(size_t size, gfp_t gfp, int align, int node,
 	}
 	if (unlikely(gfp & __GFP_ZERO))
 		memset(b, 0, size);
+
+	/* Record results */
+	if (slob_list == &free_slob_small)
+	{
+		spin_lock_irqsave(&slob_lock, flags);
+		amt_claimed[history_iterator] = size;
+		amt_free[history_iterator] = temp_amt_free * SLOB_UNIT;
+		history_iterator = (history_iterator + 1) % HISTORY_LENGTH;
+		spin_unlock_irqrestore(&slob_lock, flags);
+	}
 	return b;
 }
 
@@ -716,3 +806,23 @@ void __init kmem_cache_init_late(void)
 {
 	slab_state = FULL;
 }
+
+SYSCALL_DEFINE0(get_slob_amt_claimed)
+{
+	long sum = 0;
+	int iterator = 0;
+	for(iterator = 0; iterator < HISTORY_LENGTH; iterator++) {
+		sum += amt_claimed[iterator];
+	}
+	return sum / HISTORY_LENGTH;
+}
+
+SYSCALL_DEFINE0(get_slob_amt_free)
+{
+	long sum = 0;
+	int iterator = 0;
+	for(iterator = 0; iterator < HISTORY_LENGTH; iterator++) {
+		sum += amt_free[iterator];
+	}
+	return sum / HISTORY_LENGTH;
+}
